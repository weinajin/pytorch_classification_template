{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment pipeline\n",
    "\n",
    "1. load data: in Uncertainty class __init__. Instantiate an Uncertainty instance.\n",
    "    - load trained model\n",
    "    - for the trained model, and its validation set (w/ corresponding activations, predictions, and gt), instantiate a CulpritNeuronScore instance, for further culprit score compute\n",
    "    - load query dataset activations, predictions, gt. (gt is only used for validate the methods, in query time with user, gt is unknown)\n",
    "\n",
    "\n",
    "2. compute culprit matrix for a given trained model: get_culprit_matrix(), get_baseline() for random culprit comparison as baseline.\n",
    "    - specify: model, culprit method\n",
    "    \n",
    "    \n",
    "3. compute uncertain matrix given the culprit mtx, and the query data activations: get_uncertain_matrix()\n",
    "\n",
    "\n",
    "4. visualize the results, compute the correlation between gt error and the uncertain mtx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from culprit import *\n",
    "from uncertainty import *\n",
    "import json\n",
    "import datetime\n",
    "import plotly \n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= '1'\n",
    "models = ['skinmodel/checkpoint.pth']\n",
    "experiment_saved_path = './saved' # it has the experiment activation maps, and saved exp data as a folder\n",
    "clpt_methods = ['select']\n",
    "sim_methods = ['cosine']#, 'mi']\n",
    "gt_error_methods = ['l1']#, 'ce']\n",
    "model_path = 'skinmodel/checkpoint.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(clpt_method, sim_method, gt_error_method, model, \\\n",
    "             experiment_saved_path = './saved', \\\n",
    "             query = 'config_skin_alexnet_query.json', val = 'config_skin_alexnet_val.json', \\\n",
    "             baseline = True, query_mode = False):\n",
    "    \n",
    "    # 1. load data: in Uncertainty class init. Instantiate an Uncertainty instance\n",
    "    uncty = Uncertainty(experiment_saved_path, model_path)\n",
    "    gt_error_methods = {'l1': uncty.get_generalize_error, 'ce': uncty.get_generalize_error_ce }\n",
    "    gt, pred = uncty.get_query_gt_pred()\n",
    "    \n",
    "    # 2. compute culprit matrix for a given trained model, get_baseline() for random culprit comparison as baseline.\n",
    "    clpt_mtx = uncty.get_culprit_matrix(clpt_method)\n",
    "    # 3. compute uncertain matrix given the culprit mtx, and the query data activations\n",
    "    uncty_mtx = uncty.get_uncertain_matrix(clpt_mtx, uncty.query_actv, sim_method)\n",
    "    \n",
    "    # 2.1 baseline\n",
    "    bl_clpt_mtx = uncty.get_baseline(clpr_mtx)\n",
    "    bl_uncty_mtx = uncty.get_uncertain_matrix(bl_clpt_mtx, uncty.query_actv, sim_method)\n",
    "    uncty_mtxs.append(bl_uncty_mtx)\n",
    "    \n",
    "    # 4. prepare for vis\n",
    "    actv_map_shape = uncty.get_actv_shape()\n",
    "    \n",
    "\n",
    "    if query_mode:\n",
    "        # start interactive visualize\n",
    "        uncty.query_visulize()\n",
    "    else:\n",
    "        # visualize the save experiment results\n",
    "        timestamp = datetime.datetime.now().strftime('%m%d_%H%M%S')\n",
    "        experiment_saved_subfolder = timestamp + '_' + model_path + '_' + clpt_method + '_' + sim_method + '_' + gt_error_method\n",
    "#         uncty.experiment_results_visualize(gt_error_method, experiment_saved_path, experiment_saved_subfolder)\n",
    "        # interactive vis: select target layer, show correlation with gt\n",
    "        \n",
    "        error = gt_error_methods[gt_error_method](gt, pred)\n",
    "        plt.scatter(error.reshape(-1), uncty_mtx.reshape(-1))\n",
    "        # vis1. correlation scatter plot\n",
    "        plt.plot(uncty.error.reshape(-1))\n",
    "        plt.show()\n",
    "        plt.clf() \n",
    "        plt.close()\n",
    "        # vis2. signal plot over datapoints and their classes                 \n",
    "        plt.plot(uncty_mtx.reshape(-1))\n",
    "        plt.legend(['gt error', 'proposed_uncertainty'])\n",
    "        plt.title('the gt error and the proposed uncertainty for the query 150 images')\n",
    "        plt.show()\n",
    "        plt.clf() \n",
    "        plt.close()\n",
    "    return uncty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** actv shape (ignore dim 0 - batch size) is: [torch.Size([64, 64, 55, 55]), torch.Size([64, 192, 27, 27]), torch.Size([64, 384, 13, 13]), torch.Size([64, 256, 13, 13]), torch.Size([64, 256, 13, 13]), torch.Size([64, 4096]), torch.Size([64, 4096]), torch.Size([64, 2])] .\n",
      "*** data loaded ***\n",
      "*** Flattened actv vector shape is torch.Size([150, 9346]).\n",
      "*** actv shape (ignore dim 0 - batch size) is: [torch.Size([64, 64, 55, 55]), torch.Size([64, 192, 27, 27]), torch.Size([64, 384, 13, 13]), torch.Size([64, 256, 13, 13]), torch.Size([64, 256, 13, 13]), torch.Size([64, 4096]), torch.Size([64, 4096]), torch.Size([64, 2])] .\n",
      "*** data loaded ***\n",
      "*** label size is torch.Size([600]), right prediction is 459.\n",
      "*** feature shape is torch.Size([600, 9346]).\n",
      "*** right_actv shape is torch.Size([459, 9346]), wrong_actv shape is torch.Size([141, 9346]).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Uncertainty' object has no attribute 'get_query_gt_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9a3b34a9ba43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msim_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msim_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgt_error_method\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgt_error_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 \u001b[0muncty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclpt_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_error_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-854464e58ce7>\u001b[0m in \u001b[0;36mpipeline\u001b[0;34m(clpt_method, sim_method, gt_error_method, model, experiment_saved_path, query, val, baseline, query_mode)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0muncty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUncertainty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_saved_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mgt_error_methods\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'l1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muncty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_generalize_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ce'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0muncty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_generalize_error_ce\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muncty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_query_gt_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# 2. compute culprit matrix for a given trained model, get_baseline() for random culprit comparison as baseline.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Uncertainty' object has no attribute 'get_query_gt_pred'"
     ]
    }
   ],
   "source": [
    "uncty = None\n",
    "for model in models:\n",
    "    for clpt_method in clpt_methods:\n",
    "        for sim_method in sim_methods:\n",
    "            for gt_error_method in gt_error_methods:\n",
    "                uncty = pipeline(clpt_method, sim_method, gt_error_method, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
